{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a database of scalar values for ICRH coupling analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume working in Jupyter Lab\n",
    "%matplotlib inline \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywed as pw\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "from control_room import *\n",
    "from pulse_database import PulseDB\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database has been created in another notebook. Importing database : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database contains 131 shots, from #53566 to #54178 \n"
     ]
    }
   ],
   "source": [
    "hdf5_filename = 'databases/WEST_C3b_ICRH_pulse_data.hdf5'\n",
    "db = PulseDB(hdf5_filename)\n",
    "print(f'Database contains {len(db.pulse_list)} shots, from #{db.pulse_list[0]} to #{db.pulse_list[-1]} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a meaningfull database with pandas\n",
    "The idea is to split time in small pieces and to calculate scalar values for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_in_pieces(y, t, nb_pieces):\n",
    "    \"\"\"Split a time signel y(t) into smaller piece of length dt, and return t, average, min, max and std of each of them\"\"\"\n",
    "    y_mean_min_max, t_pieces = [], []\n",
    "    if nb_pieces > 0: \n",
    "        ts = np.array_split(np.squeeze(t), nb_pieces)\n",
    "        ys = np.array_split(np.squeeze(y), nb_pieces)\n",
    "        for (_y, _t) in zip(ys, ts):\n",
    "            t_pieces.append(np.mean(_t))\n",
    "            y_mean_min_max.append(mean_min_max(_y))\n",
    "        return np.array(y_mean_min_max), np.array(t_pieces)    \n",
    "    else:\n",
    "        return np.array([np.nan, np.nan, np.nan]), np.array([np.nan])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████▌                   | 69/131 [00:12<00:09,  6.53it/s]C:\\Users\\JH218595\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "100%|████████████████████████████████████████| 131/131 [00:20<00:00, 10.75it/s]\n"
     ]
    }
   ],
   "source": [
    "DELTA_T_BEFORE = 1  # s\n",
    "dt = 0.05  # s\n",
    "\n",
    "data_Q1 = pd.DataFrame()\n",
    "\n",
    "# generate averaged values for Q1\n",
    "for pulse in tqdm(db.pulse_list):\n",
    "    try:\n",
    "        P_IC, t_P_IC = db.get_signal(pulse, 'IC_P_Q1')\n",
    "        Rc,   t_Rc   = db.get_signal(pulse, 'IC_Rc_Q1_avg')\n",
    "        V7,  t_V7  = db.get_signal(pulse, 'Valve7')\n",
    "        V9,  t_V9  = db.get_signal(pulse, 'Valve9')\n",
    "        V10,  t_V10  = db.get_signal(pulse, 'Valve10')\n",
    "        V11,  t_V11  = db.get_signal(pulse, 'Valve11')\n",
    "        V21,  t_V21  = db.get_signal(pulse, 'Valve21')\n",
    "        nl, t_nl = db.get_signal(pulse, 'nl')\n",
    "        ip, t_ip = db.get_signal(pulse, 'Ip')\n",
    "        \n",
    "        try:  # il n'y a pas forcément de P_LH\n",
    "            P_LH, t_P_LH = db.get_signal(pulse, 'LH_P_tot')\n",
    "            if np.any(np.isnan(P_LH)):\n",
    "                P_LH = np.zeros_like(P_IC)\n",
    "                t_P_LH = t_P_IC\n",
    "        except:\n",
    "            P_LH = np.zeros_like(P_IC)\n",
    "            t_P_LH = t_P_IC\n",
    "        \n",
    "        Rext_upper, t_Rext_upper = db.get_signal(pulse, 'Rext_upper')\n",
    "        Rext_median, t_Rext_median = db.get_signal(pulse, 'Rext_median')\n",
    "        Rext_lower, t_Rext_lower = db.get_signal(pulse, 'Rext_lower')\n",
    "        Zgeo, t_Zgeo = db.get_signal(pulse, 'Zgeo')\n",
    "        IC_Positions, _ = db.get_signal(pulse, 'IC_Positions')\n",
    "        IC_Frequencies, _ = np.round(db.get_signal(pulse, 'IC_Frequencies'), decimals=1)\n",
    "        \n",
    "        C_LU, t_C_LU = db.get_signal(pulse, 'IC_Capa_Q1_left_upper')\n",
    "        C_LL, t_C_LL = db.get_signal(pulse, 'IC_Capa_Q1_left_lower')\n",
    "        C_RU, t_C_RU = db.get_signal(pulse, 'IC_Capa_Q1_right_upper')\n",
    "        C_RL, t_C_RL = db.get_signal(pulse, 'IC_Capa_Q1_right_lower')\n",
    "\n",
    "        try:\n",
    "            Lang1, t_Lang1 = db.get_signal(pulse, 'Langmuir_LHCD1')\n",
    "            Lang2, t_Lang2 = db.get_signal(pulse, 'Langmuir_LHCD2')\n",
    "            Lang3, t_Lang3 = db.get_signal(pulse, 'Langmuir_LHCD3')\n",
    "            Lang4, t_Lang4 = db.get_signal(pulse, 'Langmuir_LHCD4')\n",
    "            Lang5, t_Lang5 = db.get_signal(pulse, 'Langmuir_LHCD5')\n",
    "            Lang6, t_Lang6 = db.get_signal(pulse, 'Langmuir_LHCD6')\n",
    "            Lang7, t_Lang7 = db.get_signal(pulse, 'Langmuir_LHCD7')\n",
    "            Lang8, t_Lang8 = db.get_signal(pulse, 'Langmuir_LHCD8')\n",
    "        except:\n",
    "            Lang1, t_Lang1 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang2, t_Lang2 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang3, t_Lang3 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang4, t_Lang4 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang5, t_Lang5 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang6, t_Lang6 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang7, t_Lang7 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang8, t_Lang8 = np.zeros_like(P_IC), t_P_IC\n",
    "        \n",
    "        t_start = db.get_attr(pulse, 'IC_P_Q1', 't_start')\n",
    "        t_stop = db.get_attr(pulse, 'IC_P_Q1', 't_stop')\n",
    "        \n",
    "        if (t_start > 0) and (t_stop > 0):\n",
    "            # filter the signals to the time of interest\n",
    "            _P_IC, _t_P_IC = in_between(P_IC, t_P_IC, t_start, t_stop)\n",
    "            _Rc,   _t_Rc   = in_between(Rc, t_Rc, t_start, t_stop)\n",
    "            _V7,  _t_V7  = in_between(V7, t_V7, t_start, t_stop)\n",
    "            _V9,  _t_V9  = in_between(V9, t_V9, t_start, t_stop)\n",
    "            _V10,  _t_V10  = in_between(V10, t_V10, t_start, t_stop)\n",
    "            _V11,  _t_V11  = in_between(V11, t_V11, t_start, t_stop)\n",
    "            _V21,  _t_V21  = in_between(V21, t_V21, t_start, t_stop)\n",
    "            _V7_before,  _t_V7_before  = in_between(V7, t_V7, t_start - DELTA_T_BEFORE, t_stop - DELTA_T_BEFORE)\n",
    "            _V10_before,  _t_V10_before  = in_between(V10, t_V10, t_start - DELTA_T_BEFORE, t_stop - DELTA_T_BEFORE)\n",
    "            _V11_before,  _t_V11_before  = in_between(V11, t_V11, t_start - DELTA_T_BEFORE, t_stop - DELTA_T_BEFORE)\n",
    "            _V21_before,  _t_V21_before  = in_between(V21, t_V21, t_start - DELTA_T_BEFORE, t_stop - DELTA_T_BEFORE)\n",
    "            _nl, _t_nl = in_between(nl, t_nl, t_start, t_stop)\n",
    "            _ip, _t_ip = in_between(ip, t_ip, t_start, t_stop)\n",
    "            \n",
    "            _P_LH, _t_P_LH = in_between(P_LH, t_P_LH, t_start, t_stop)\n",
    "            _Rext_upper, _t_Rext_upper = in_between(Rext_upper, t_Rext_upper, t_start, t_stop)\n",
    "            _Rext_median, _t_Rext_median = in_between(Rext_median, t_Rext_median, t_start, t_stop)\n",
    "            _Rext_lower, _t_Rext_lower = in_between(Rext_lower, t_Rext_lower, t_start, t_stop)\n",
    "            _Zgeo, _t_Zgeo = in_between(Zgeo, t_Zgeo, t_start, t_stop)\n",
    "            \n",
    "            _C_LU, _t_C_LU = in_between(C_LU, t_C_LU, t_start, t_stop)\n",
    "            _C_LL, _t_C_LL = in_between(C_LL, t_C_LL, t_start, t_stop)\n",
    "            _C_RU, _t_C_RU = in_between(C_RU, t_C_RU, t_start, t_stop)\n",
    "            _C_RL, _t_C_RL = in_between(C_RL, t_C_RL, t_start, t_stop)\n",
    "            # did we used automatic matching? Check if capacitors are all almost constant. If yes, means no auto matching used for this shot\n",
    "            auto_matching = not (np.allclose(_C_LU, _C_LU[0]) and np.allclose(_C_LL, _C_LL[0]) and np.allclose(_C_RU, _C_RU[0]) and np.allclose(_C_RL, _C_RL[0]))\n",
    "\n",
    "            _Lang1, _t_Lang1 = in_between(Lang1, t_Lang1, t_start, t_stop)\n",
    "            _Lang2, _t_Lang2 = in_between(Lang2, t_Lang2, t_start, t_stop)\n",
    "            _Lang3, _t_Lang3 = in_between(Lang3, t_Lang3, t_start, t_stop)\n",
    "            _Lang4, _t_Lang4 = in_between(Lang4, t_Lang4, t_start, t_stop)\n",
    "            _Lang5, _t_Lang5 = in_between(Lang5, t_Lang5, t_start, t_stop)\n",
    "            _Lang6, _t_Lang6 = in_between(Lang6, t_Lang6, t_start, t_stop)\n",
    "            _Lang7, _t_Lang7 = in_between(Lang7, t_Lang7, t_start, t_stop)\n",
    "            _Lang8, _t_Lang8 = in_between(Lang8, t_Lang8, t_start, t_stop)\n",
    "            \n",
    "            # split signals in little pieces\n",
    "            nb_pieces = np.round((_t_P_IC[-1] - _t_P_IC[0])/dt)\n",
    "            _P_IC_mean_min_maxs, _t_P_ICs = split_in_pieces(_P_IC, _t_P_IC, nb_pieces)\n",
    "            _Rc_mean_min_maxs, _ = split_in_pieces(_Rc, _t_Rc, nb_pieces)\n",
    "            _V7_mean_min_maxs, _ = split_in_pieces(_V7, _t_V7, nb_pieces)\n",
    "            _V9_mean_min_maxs, _ = split_in_pieces(_V9, _t_V9, nb_pieces)\n",
    "            _V10_mean_min_maxs, _ = split_in_pieces(_V10, _t_V10, nb_pieces)\n",
    "            _V11_mean_min_maxs, _ = split_in_pieces(_V11, _t_V11, nb_pieces)\n",
    "            _V21_mean_min_maxs, _ = split_in_pieces(_V21, _t_V21, nb_pieces)\n",
    "            _V7_before_mean_min_maxs, _ = split_in_pieces(_V7_before, _t_V7_before, nb_pieces)\n",
    "            _V10_before_mean_min_maxs, _ = split_in_pieces(_V10_before, _t_V10_before, nb_pieces)\n",
    "            _V11_before_mean_min_maxs, _ = split_in_pieces(_V11_before, _t_V11_before, nb_pieces)\n",
    "            _V21_before_mean_min_maxs, _ = split_in_pieces(_V21_before, _t_V21_before, nb_pieces)\n",
    "            _nl_mean_min_max, _ = split_in_pieces(_nl, _t_nl, nb_pieces)\n",
    "            _ip_mean_min_max, _ = split_in_pieces(_ip, _t_ip, nb_pieces)\n",
    "            \n",
    "            _P_LH_mean_min_maxs, _ = split_in_pieces(_P_LH, _t_P_LH, nb_pieces)\n",
    "            _Rext_upper_mean_min_maxs, _ = split_in_pieces(_Rext_upper, _t_Rext_upper, nb_pieces)\n",
    "            _Rext_median_mean_min_maxs, _ = split_in_pieces(_Rext_median, _t_Rext_median, nb_pieces)\n",
    "            _Rext_lower_mean_min_maxs, _ = split_in_pieces(_Rext_lower, _t_Rext_lower, nb_pieces)\n",
    "            _Zgeo_mean_min_maxs, _ = split_in_pieces(_Zgeo, _t_Zgeo, nb_pieces)            \n",
    "\n",
    "            _Lang1_avg, _ =  split_in_pieces(_Lang1, _t_Lang1, nb_pieces)\n",
    "            _Lang2_avg, _ =  split_in_pieces(_Lang2, _t_Lang2, nb_pieces)\n",
    "            _Lang3_avg, _ =  split_in_pieces(_Lang3, _t_Lang3, nb_pieces)\n",
    "            _Lang4_avg, _ =  split_in_pieces(_Lang4, _t_Lang4, nb_pieces)\n",
    "            _Lang5_avg, _ =  split_in_pieces(_Lang5, _t_Lang5, nb_pieces)\n",
    "            _Lang6_avg, _ =  split_in_pieces(_Lang6, _t_Lang6, nb_pieces)\n",
    "            _Lang7_avg, _ =  split_in_pieces(_Lang7, _t_Lang7, nb_pieces)\n",
    "            _Lang8_avg, _ =  split_in_pieces(_Lang8, _t_Lang8, nb_pieces)\n",
    "            \n",
    "            # add signals to database\n",
    "            if not np.any(np.isnan(_P_IC_mean_min_maxs)):\n",
    "                rows = {'pulse': pulse,\n",
    "                        't': _t_P_ICs, \n",
    "                        'P_IC_avg': _P_IC_mean_min_maxs[:,0],                    \n",
    "                        'Rc_avg': _Rc_mean_min_maxs[:,0],\n",
    "                        'V7_avg': _V7_mean_min_maxs[:,0],\n",
    "                        'V9_avg': _V9_mean_min_maxs[:,0],\n",
    "                        'V10_avg': _V10_mean_min_maxs[:,0],\n",
    "                        'V11_avg': _V11_mean_min_maxs[:,0],\n",
    "                        'V21_avg': _V21_mean_min_maxs[:,0],\n",
    "                        'V7_before_avg': _V7_before_mean_min_maxs[:,0],\n",
    "                        'V10_before_avg': _V10_before_mean_min_maxs[:,0],\n",
    "                        'V11_before_avg': _V11_before_mean_min_maxs[:,0],\n",
    "                        'V21_before_avg': _V21_before_mean_min_maxs[:,0],\n",
    "                        'P_LH_avg': _P_LH_mean_min_maxs[:,0],\n",
    "                        'Rext_upper': _Rext_upper_mean_min_maxs[:,0],\n",
    "                        'Rext_median': _Rext_median_mean_min_maxs[:,0],\n",
    "                        'Rext_lower': _Rext_lower_mean_min_maxs[:,0],\n",
    "                        'Zgeo': _Zgeo_mean_min_maxs[:,0],\n",
    "                        'R_Q1': IC_Positions[0],\n",
    "                        'R_Q2': IC_Positions[1],\n",
    "                        'R_Q4': IC_Positions[2],\n",
    "                        'freq_Q1': IC_Frequencies[0],\n",
    "                        'freq_Q2': IC_Frequencies[1],\n",
    "                        'freq_Q4': IC_Frequencies[2],\n",
    "                        'gap_median': IC_Positions[0]*1e3 - _Rext_median_mean_min_maxs[:,0],\n",
    "                        'nl_avg': _nl_mean_min_max[:,0],\n",
    "                        'Ip_avg': _ip_mean_min_max[:,0],\n",
    "                        'auto_matching': int(auto_matching),\n",
    "                        'Lang1_avg': _Lang1_avg[:,0], 'Lang2_avg': _Lang2_avg[:,0], 'Lang3_avg': _Lang3_avg[:,0], 'Lang4_avg': _Lang4_avg[:,0],\n",
    "                        'Lang5_avg': _Lang5_avg[:,0], 'Lang6_avg': _Lang6_avg[:,0], 'Lang7_avg': _Lang7_avg[:,0], 'Lang8_avg': _Lang8_avg[:,0],\n",
    "                       }\n",
    "                df = pd.DataFrame(rows)\n",
    "                \n",
    "                data_Q1 = data_Q1.append(df)\n",
    "            \n",
    "\n",
    "    except KeyError as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 131/131 [00:20<00:00,  6.95it/s]\n"
     ]
    }
   ],
   "source": [
    "DELTA_T_BEFORE = 1  # s\n",
    "\n",
    "dt = 0.05  # s\n",
    "\n",
    "data_Q2 = pd.DataFrame()\n",
    "\n",
    "# generate averaged values for Q2\n",
    "for pulse in tqdm(db.pulse_list):\n",
    "    text = pulse\n",
    "    try:\n",
    "        P_IC, t_P_IC = db.get_signal(pulse, 'IC_P_Q2')\n",
    "        Rc,   t_Rc   = db.get_signal(pulse, 'IC_Rc_Q2_avg')\n",
    "        V7,  t_V7  = db.get_signal(pulse, 'Valve7')\n",
    "        V9,  t_V9  = db.get_signal(pulse, 'Valve9')\n",
    "        V10,  t_V10  = db.get_signal(pulse, 'Valve10')\n",
    "        V11,  t_V11  = db.get_signal(pulse, 'Valve11')\n",
    "        V21,  t_V21  = db.get_signal(pulse, 'Valve21')\n",
    "        nl, t_nl = db.get_signal(pulse, 'nl')\n",
    "        ip, t_ip = db.get_signal(pulse, 'Ip')\n",
    "        \n",
    "        Rext_upper, t_Rext_upper = db.get_signal(pulse, 'Rext_upper')\n",
    "        Rext_median, t_Rext_median = db.get_signal(pulse, 'Rext_median')\n",
    "        Rext_lower, t_Rext_lower = db.get_signal(pulse, 'Rext_lower')\n",
    "        Zgeo, t_Zgeo = db.get_signal(pulse, 'Zgeo')\n",
    "        IC_Positions, _ = db.get_signal(pulse, 'IC_Positions')\n",
    "        IC_Frequencies, _ = np.round(db.get_signal(pulse, 'IC_Frequencies'), decimals=1)\n",
    "        \n",
    "        try: # il n'y a pas forcément de P_LH\n",
    "            P_LH, t_P_LH = db.get_signal(pulse, 'LH_P_tot')\n",
    "            if np.any(np.isnan(P_LH)):\n",
    "                P_LH = np.zeros_like(P_IC)\n",
    "                t_P_LH = t_P_IC\n",
    "        except:\n",
    "            P_LH = np.zeros_like(P_IC)\n",
    "            t_P_LH = t_P_IC\n",
    "        \n",
    "        C_LU, t_C_LU = db.get_signal(pulse, 'IC_Capa_Q2_left_upper')\n",
    "        C_LL, t_C_LL = db.get_signal(pulse, 'IC_Capa_Q2_left_lower')\n",
    "        C_RU, t_C_RU = db.get_signal(pulse, 'IC_Capa_Q2_right_upper')\n",
    "        C_RL, t_C_RL = db.get_signal(pulse, 'IC_Capa_Q2_right_lower')\n",
    "\n",
    "        try:\n",
    "            Lang1, t_Lang1 = db.get_signal(pulse, 'Langmuir_LHCD1')\n",
    "            Lang2, t_Lang2 = db.get_signal(pulse, 'Langmuir_LHCD2')\n",
    "            Lang3, t_Lang3 = db.get_signal(pulse, 'Langmuir_LHCD3')\n",
    "            Lang4, t_Lang4 = db.get_signal(pulse, 'Langmuir_LHCD4')\n",
    "            Lang5, t_Lang5 = db.get_signal(pulse, 'Langmuir_LHCD5')\n",
    "            Lang6, t_Lang6 = db.get_signal(pulse, 'Langmuir_LHCD6')\n",
    "            Lang7, t_Lang7 = db.get_signal(pulse, 'Langmuir_LHCD7')\n",
    "            Lang8, t_Lang8 = db.get_signal(pulse, 'Langmuir_LHCD8')\n",
    "        except:\n",
    "            Lang1, t_Lang1 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang2, t_Lang2 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang3, t_Lang3 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang4, t_Lang4 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang5, t_Lang5 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang6, t_Lang6 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang7, t_Lang7 = np.zeros_like(P_IC), t_P_IC\n",
    "            Lang8, t_Lang8 = np.zeros_like(P_IC), t_P_IC\n",
    "            \n",
    "        t_start = db.get_attr(pulse, 'IC_P_Q2', 't_start')\n",
    "        t_stop = db.get_attr(pulse, 'IC_P_Q2', 't_stop')\n",
    "        \n",
    "        if (t_start > 0) and (t_stop > 0):\n",
    "            # filter the signals to the time of interest\n",
    "            _P_IC, _t_P_IC = in_between(P_IC, t_P_IC, t_start, t_stop)\n",
    "            _P_LH, _t_P_LH = in_between(P_LH, t_P_LH, t_start, t_stop)\n",
    "            _Rc,   _t_Rc   = in_between(Rc, t_Rc, t_start, t_stop)\n",
    "            _V7,  _t_V7  = in_between(V7, t_V7, t_start, t_stop)\n",
    "            _V9,  _t_V9  = in_between(V9, t_V9, t_start, t_stop)\n",
    "            _V10,  _t_V10  = in_between(V10, t_V10, t_start, t_stop)\n",
    "            _V11,  _t_V11  = in_between(V11, t_V11, t_start, t_stop)\n",
    "            _V21,  _t_V21  = in_between(V21, t_V21, t_start, t_stop)\n",
    "            _V7_before,  _t_V7_before  = in_between(V7, t_V7, t_start - DELTA_T_BEFORE, t_stop - DELTA_T_BEFORE)\n",
    "            _V10_before,  _t_V10_before  = in_between(V10, t_V10, t_start - DELTA_T_BEFORE, t_stop - DELTA_T_BEFORE)\n",
    "            _V11_before,  _t_V11_before  = in_between(V11, t_V11, t_start - DELTA_T_BEFORE, t_stop - DELTA_T_BEFORE)\n",
    "            _V21_before,  _t_V21_before  = in_between(V21, t_V21, t_start - DELTA_T_BEFORE, t_stop - DELTA_T_BEFORE)\n",
    "            _nl, _t_nl = in_between(nl, t_nl, t_start, t_stop)\n",
    "            _ip, _t_ip = in_between(ip, t_ip, t_start, t_stop)\n",
    "            \n",
    "            _Rext_upper, _t_Rext_upper = in_between(Rext_upper, t_Rext_upper, t_start, t_stop)\n",
    "            _Rext_median, _t_Rext_median = in_between(Rext_median, t_Rext_median, t_start, t_stop)\n",
    "            _Rext_lower, _t_Rext_lower = in_between(Rext_lower, t_Rext_lower, t_start, t_stop)\n",
    "            _Zgeo, _t_Zgeo = in_between(Zgeo, t_Zgeo, t_start, t_stop)\n",
    "\n",
    "            _C_LU, _t_C_LU = in_between(C_LU, t_C_LU, t_start, t_stop)\n",
    "            _C_LL, _t_C_LL = in_between(C_LL, t_C_LL, t_start, t_stop)\n",
    "            _C_RU, _t_C_RU = in_between(C_RU, t_C_RU, t_start, t_stop)\n",
    "            _C_RL, _t_C_RL = in_between(C_RL, t_C_RL, t_start, t_stop)\n",
    "            # did we used automatic matching? Check if capacitors are all almost constant. If yes, means no auto matching used for this shot\n",
    "            auto_matching = not (np.allclose(_C_LU, _C_LU[0]) and np.allclose(_C_LL, _C_LL[0]) and np.allclose(_C_RU, _C_RU[0]) and np.allclose(_C_RL, _C_RL[0]))\n",
    "            \n",
    "            _Lang1, _t_Lang1 = in_between(Lang1, t_Lang1, t_start, t_stop)\n",
    "            _Lang2, _t_Lang2 = in_between(Lang2, t_Lang2, t_start, t_stop)\n",
    "            _Lang3, _t_Lang3 = in_between(Lang3, t_Lang3, t_start, t_stop)\n",
    "            _Lang4, _t_Lang4 = in_between(Lang4, t_Lang4, t_start, t_stop)\n",
    "            _Lang5, _t_Lang5 = in_between(Lang5, t_Lang5, t_start, t_stop)\n",
    "            _Lang6, _t_Lang6 = in_between(Lang6, t_Lang6, t_start, t_stop)\n",
    "            _Lang7, _t_Lang7 = in_between(Lang7, t_Lang7, t_start, t_stop)\n",
    "            _Lang8, _t_Lang8 = in_between(Lang8, t_Lang8, t_start, t_stop)\n",
    "            \n",
    "            # split signals in little pieces\n",
    "            nb_pieces = np.round((_t_P_IC[-1] - _t_P_IC[0])/dt)\n",
    "            _P_IC_mean_min_maxs, _t_P_ICs = split_in_pieces(_P_IC, _t_P_IC, nb_pieces)\n",
    "            _P_LH_mean_min_maxs, _ = split_in_pieces(_P_LH, _t_P_LH, nb_pieces)\n",
    "            _Rc_mean_min_maxs, _ = split_in_pieces(_Rc, _t_Rc, nb_pieces)\n",
    "            _V7_mean_min_maxs, _ = split_in_pieces(_V7, _t_V7, nb_pieces)\n",
    "            _V9_mean_min_maxs, _ = split_in_pieces(_V9, _t_V9, nb_pieces)\n",
    "            _V10_mean_min_maxs, _ = split_in_pieces(_V10, _t_V10, nb_pieces)\n",
    "            _V11_mean_min_maxs, _ = split_in_pieces(_V11, _t_V11, nb_pieces)\n",
    "            _V21_mean_min_maxs, _ = split_in_pieces(_V21, _t_V21, nb_pieces)\n",
    "            _V7_before_mean_min_maxs, _ = split_in_pieces(_V7_before, _t_V7_before, nb_pieces)\n",
    "            _V10_before_mean_min_maxs, _ = split_in_pieces(_V10_before, _t_V10_before, nb_pieces)\n",
    "            _V11_before_mean_min_maxs, _ = split_in_pieces(_V11_before, _t_V11_before, nb_pieces)\n",
    "            _V21_before_mean_min_maxs, _ = split_in_pieces(_V21_before, _t_V21_before, nb_pieces)\n",
    "            _nl_mean_min_max, _ = split_in_pieces(_nl, _t_nl, nb_pieces)\n",
    "            _ip_mean_min_max, _ = split_in_pieces(_ip, _t_ip, nb_pieces)\n",
    "            \n",
    "            _Rext_upper_mean_min_maxs, _ = split_in_pieces(_Rext_upper, _t_Rext_upper, nb_pieces)\n",
    "            _Rext_median_mean_min_maxs, _ = split_in_pieces(_Rext_median, _t_Rext_median, nb_pieces)\n",
    "            _Rext_lower_mean_min_maxs, _ = split_in_pieces(_Rext_lower, _t_Rext_lower, nb_pieces)\n",
    "            _Zgeo_mean_min_maxs, _ = split_in_pieces(_Zgeo, _t_Zgeo, nb_pieces)\n",
    "            \n",
    "            _Lang1_avg, _ =  split_in_pieces(_Lang1, _t_Lang1, nb_pieces)\n",
    "            _Lang2_avg, _ =  split_in_pieces(_Lang2, _t_Lang2, nb_pieces)\n",
    "            _Lang3_avg, _ =  split_in_pieces(_Lang3, _t_Lang3, nb_pieces)\n",
    "            _Lang4_avg, _ =  split_in_pieces(_Lang4, _t_Lang4, nb_pieces)\n",
    "            _Lang5_avg, _ =  split_in_pieces(_Lang5, _t_Lang5, nb_pieces)\n",
    "            _Lang6_avg, _ =  split_in_pieces(_Lang6, _t_Lang6, nb_pieces)\n",
    "            _Lang7_avg, _ =  split_in_pieces(_Lang7, _t_Lang7, nb_pieces)\n",
    "            _Lang8_avg, _ =  split_in_pieces(_Lang8, _t_Lang8, nb_pieces)\n",
    "            \n",
    "            # add signals to database\n",
    "            if not np.any(np.isnan(_P_IC_mean_min_maxs)):\n",
    "                rows = {'pulse': pulse,\n",
    "                        't': _t_P_ICs, \n",
    "                        'P_IC_avg': _P_IC_mean_min_maxs[:,0],                    \n",
    "                        'Rc_avg': _Rc_mean_min_maxs[:,0],\n",
    "                        'V7_avg': _V7_mean_min_maxs[:,0],\n",
    "                        'V9_avg': _V9_mean_min_maxs[:,0],\n",
    "                        'V10_avg': _V10_mean_min_maxs[:,0],\n",
    "                        'V11_avg': _V11_mean_min_maxs[:,0],\n",
    "                        'V21_avg': _V21_mean_min_maxs[:,0],\n",
    "                        'V7_before_avg': _V7_before_mean_min_maxs[:,0],\n",
    "                        'V10_before_avg': _V10_before_mean_min_maxs[:,0],\n",
    "                        'V11_before_avg': _V11_before_mean_min_maxs[:,0],\n",
    "                        'V21_before_avg': _V21_before_mean_min_maxs[:,0],\n",
    "                        'P_LH_avg': _P_LH_mean_min_maxs[:,0],\n",
    "                        'Rext_upper': _Rext_upper_mean_min_maxs[:,0],\n",
    "                        'Rext_median': _Rext_median_mean_min_maxs[:,0],\n",
    "                        'Rext_lower': _Rext_lower_mean_min_maxs[:,0],\n",
    "                        'Zgeo': _Zgeo_mean_min_maxs[:,0],\n",
    "                        'R_Q1': IC_Positions[0],\n",
    "                        'R_Q2': IC_Positions[1],\n",
    "                        'R_Q4': IC_Positions[2],\n",
    "                        'freq_Q1': IC_Frequencies[0],\n",
    "                        'freq_Q2': IC_Frequencies[1],\n",
    "                        'freq_Q4': IC_Frequencies[2],\n",
    "                        'gap_median': IC_Positions[1]*1e3 - _Rext_median_mean_min_maxs[:,0],\n",
    "                        'nl_avg': _nl_mean_min_max[:,0],\n",
    "                        'Ip_avg': _ip_mean_min_max[:,0],\n",
    "                        'auto_matching': int(auto_matching),\n",
    "                        'Lang1_avg': _Lang1_avg[:,0], 'Lang2_avg': _Lang2_avg[:,0], 'Lang3_avg': _Lang3_avg[:,0], 'Lang4_avg': _Lang4_avg[:,0],\n",
    "                        'Lang5_avg': _Lang5_avg[:,0], 'Lang6_avg': _Lang6_avg[:,0], 'Lang7_avg': _Lang7_avg[:,0], 'Lang8_avg': _Lang8_avg[:,0],\n",
    "                       }\n",
    "                df = pd.DataFrame(rows)\n",
    "                \n",
    "                data_Q2 = data_Q2.append(df)\n",
    "            \n",
    "\n",
    "    except KeyError as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Q1.to_csv('WEST_C3b_database_resumed_parameters_Q1.csv')\n",
    "data_Q2.to_csv('WEST_C3b_database_resumed_parameters_Q2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
